{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C1_W3_Lab_1_improving_accuracy_using_convolutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauraAriasFdez/TensorFlowSpecialization/blob/main/Improving_accuracy_using_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "More about the math behind Convolution Neural Network here: https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s22jUeWUW_cI"
      },
      "source": [
        "1. Deep Neural Netwokr (DNN)\n",
        "2. Improving Computer Vision Accuracy using Convolutions & Pooling\n",
        "3. Visualizing the Convolutions and Pooling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAwJQmSZSBNQ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6gHiH-I7uFa"
      },
      "source": [
        "## **1. Deep Neural Network (DNN)**\n",
        "In the previous lessons you saw how to do fashion recognition using a Deep Neural Network (DNN) containing three layers -- the input layer (in the shape of the data), the output layer (in the shape of the desired output) and a hidden layer. You experimented with the impact of different sizes of hidden layer, number of training epochs etc on the final accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcsRtq9OLorS"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFDMnG1X36aj",
        "outputId": "fe6952d5-4918-4ded-af1e-31d4f0dc526a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 3ms/step - loss: 0.4988 - accuracy: 0.8250\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3782 - accuracy: 0.8626\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3369 - accuracy: 0.8777\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3133 - accuracy: 0.8848\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2939 - accuracy: 0.8906\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0f2nwDlSDWz"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zldEXSsF8Noz"
      },
      "source": [
        "## **2. Improving Computer Vision Accuracy using Convolutions & Pooling**\n",
        "\n",
        "Applying Convolutions on top of our Deep neural network will make training:\n",
        "- It depends on many factors. It might make your training faster or slower, and a poorly designed Convolutional layer may even be less efficient than a plain DNN!\n",
        "\n",
        "### ***2.1 Convolution***\n",
        "\n",
        "> In short, you take an ***kernel*** (usually 3x3 or 5x5) and pass it over the image. By changing the underlying pixels based on the formula within that matrix, you can do things like edge detection.\n",
        "\n",
        "> ***This is perfect for computer vision,  because you'll just train on the highlighted features by the kernel.***\n",
        "\n",
        "---\n",
        "\n",
        "### ***2.2 Pooling***\n",
        "> Pooling is a way of compressing an image, in which you take 4 pixels near each other an only choose the pixel with highest value\n",
        "---\n",
        "\n",
        "### ***2.3 Thee concept of Convolutional Neural Networks***\n",
        "Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate.\n",
        "1. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "2. https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0tFgT1MMKi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef5a064-a55e-4446-a681-a044d0aefeac"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "## 1. Load the data\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "## 2. Normalize data \n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "## 3. Make Model\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "  ## specify first convolution \n",
        "      # we want 64 filters  that are 3 by 3 \n",
        "      # activation function is relu = throw away negative vlaues\n",
        "      # 28 by 28 = input shape\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "\n",
        "  # Compressed the image by taking a 2 by 2 set of pixels and only keep the highest\n",
        "    # it will comrpessed the image by 1/4\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "  ## Flat the image to start training \n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "## INSPECT MODEL Model \n",
        "  # see the journey/size of image thorugh the convolutions \n",
        "model.summary()\n",
        "\n",
        "## 4. Train/Fit Model \n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "## 5. Test Model \n",
        "test_loss = model.evaluate(test_images, test_labels)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 43s 9ms/step - loss: 0.4374 - accuracy: 0.8393\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2915 - accuracy: 0.8929\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2448 - accuracy: 0.9101\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2158 - accuracy: 0.9203\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1871 - accuracy: 0.9311\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2551 - accuracy: 0.9103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34v2XwyEThKc"
      },
      "source": [
        "### Let´s analyze the code above for model.summary()\n",
        "```\n",
        "Layer(type)       Output Shape   \n",
        "################################################   \n",
        "conv2d (Conv2D)       (None, 26, 26, 64)                                       \n",
        " max_pooling2d        (None, 13, 13, 64)                                            \n",
        "\n",
        "conv2d_1 (Conv2D)     (None, 11, 11, 64)                      \n",
        " max_pooling2d_1      (None, 5, 5, 64)                  \n",
        "\n",
        "flatten (Flatten)     (None, 1600)                                   \n",
        " dense (Dense)        (None, 128)                       \n",
        " dense_1 (Dense)      (None, 10)                                                                                 \n",
        "```\n",
        "\n",
        "- Even though the date is 28 by 28 in the 1st layer the output is 26 by 26. The reson behind this is the filter is a 3 by 3 filters, meaning the boder cannot be calculated \n",
        "  - if the filter was 5 by 5, we would have 24 by 24 \n",
        "\n",
        "- The pooling compressing the image by 1/4\n",
        "\n",
        "\n",
        "- The last max pooling ends up creating 64 images of 5 by 5 in size, therefore instead of 1 single image of 28 by 28, we know have 64 images/img 5 by 5 = 1600\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlmsrEuHWmAv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXx_LX3SAlFs"
      },
      "source": [
        "##**3. Visualizing the Convolutions and Pooling**\n",
        "\n",
        "This code will show us the convolutions graphically. \n",
        "\n",
        "- The print (test_labels[:100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-6nX4QsOku6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5944db1-b3ad-45bc-c5cc-a8218d0a7c35"
      },
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FGsHhv6JvDx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "6b84e89f-05b3-4654-9969-50c1b57dd7fe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "\n",
        "# images of training data we want to display\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=7\n",
        "THIRD_IMAGE=26\n",
        "#  which convolution/filter you want to display (remember our model has 64)\n",
        "CONVOLUTION_NUMBER = 3\n",
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "\n",
        "\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[2,x].grid(False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KVPZqgHo5Ux"
      },
      "source": [
        "### EXERCISES\n",
        "\n",
        "1. ***Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.*** \n",
        "\n",
        "Higher number of filters leads to a higher training accuarcy but it leads to overfitting as testing accuarcy decreases\n",
        "\n",
        "-  when there are 64 filters:\n",
        "    - training data: loss 0.0132 - accuracy: 0.9957\n",
        "    - testing data:   loss: 0.0500 - accuracy: 0.9842\n",
        "- when there are 32 filters: \n",
        "    - training data: loss: 0.0154 - accuracy: 0.9951\n",
        "    - testing data:loss: 0.0481 - accuracy: 0.9855\n",
        " \n",
        "- when there are 16 filters: \n",
        "  - training data: loss: 0.0185 - accuracy: 0.9942\n",
        "  - testing data:loss: 0.0392 - accuracy: 0.9865\n",
        "\n",
        "\n",
        "(USING 16 FILTERS)\n",
        "2. ***Remove the final Convolution. What impact will this have on accuracy or training time?*** \n",
        "\n",
        "Removing the convolution will lead to a much faster training time, yet it will lead to worse accuarcy\n",
        "  - training data: loss: 0.0918 - accuracy: 0.9720\n",
        "  - testing data: loss: 0.1028 - accuracy: 0.9675\n",
        "\n",
        "3. ***How about adding more Convolutions? What impact do you think this will have? Experiment with it.*** \n",
        "\n",
        "Adding another convolution layer will lead to a higher training accuarcy, yet it will to a worse testing accuarcy (OVERFITTING)\n",
        "  - training data: loss: 0.0245 - accuracy: 0.9923\n",
        "  - testing data: loss: 0.0378 - accuracy: 0.9872\n",
        "\n",
        "\n",
        "4. ***In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpYRidBXpBPM",
        "outputId": "9ee2db5c-f71b-4060-8628-39da43597f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  \n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.1716 - accuracy: 0.9496\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0556 - accuracy: 0.9826\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0398 - accuracy: 0.9872\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0316 - accuracy: 0.9895\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0245 - accuracy: 0.9923\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9872\n",
            "0.9872000217437744\n"
          ]
        }
      ]
    }
  ]
}